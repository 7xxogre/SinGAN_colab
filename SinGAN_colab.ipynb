{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SinGAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOXZlv41KRL3SU2wnMVFWDY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"pZI3JBnLHKdD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627008045447,"user_tz":-540,"elapsed":502,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}},"outputId":"5b5419cd-6674-4b72-cc2e-9c1aae8abb65"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OpFjeQXkG2_7","executionInfo":{"status":"ok","timestamp":1627008045447,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["from datetime import datetime\n","import os\n","import numpy as np\n","from glob import glob\n","from PIL import Image\n","\n","import torchvision.transforms as transforms\n","import torch.utils.data as data\n","\n","import torch\n","from torch import autograd\n","from torch.nn import functional as F\n","from torch import nn\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","import torch.utils.data"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"MH-sa9lXH39v","executionInfo":{"status":"ok","timestamp":1627008046733,"user_tz":-540,"elapsed":2,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["data_dir = '/content/gdrive/MyDrive/SinGAN_data'\n","load_model = None\n","gantype = 'zerogp'\n","gpu = 0\n","validation = 0\n","img_size_min = 25\n","img_size_max = 250"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDkLV-HmHJMh","executionInfo":{"status":"ok","timestamp":1627008047176,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["\n","if load_model is not None:\n","    this_time_model = load_model\n","else:\n","    this_time_model = f'SinGAN_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}_{gantype}'\n","if os.path.isdir('./logs') is False:\n","    os.makedirs('./logs')\n","if os.path.isdir('./results') is False:\n","    os.makedirs('./results')\n","if load_model is None:\n","    os.makedirs(os.path.join('./logs', this_time_model))      \n","if os.path.isdir(os.path.join('./results', this_time_model)) is False:\n","    os.makedirs(os.path.join('./results', this_time_model)) \n","\n","log_dir = os.path.join('./logs', this_time_model)\n","res_dir = os.path.join('./results', this_time_model)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHLUS9XuIkOf","executionInfo":{"status":"ok","timestamp":1627009442992,"user_tz":-540,"elapsed":490,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["\n","class SinDataset(data.Dataset):\n","\n","    def __init__(self, dir, transform):\n","        self.data_dir = dir\n","        self.transform = transform\n","        self.image_dir = sorted(glob(os.path.join(self.data_dir, '*.jpg')))[0]\n","    \n","    def __len__(self):\n","        return len(self.image_dir)\n","\n","    def __getitem__(self, idx):\n","        with open(self.image_dir, 'rb') as f:\n","            img = Image.open(f)\n","            img = img.convert('RGB')\n","            return self.transform(img)\n","\n","\n","def get_dataset(data_dir):\n","    # image processing\n","    train_transforms = transforms.Compose([transforms.Resize((256,256)),\n","                                           transforms.ToTensor(),\n","                                           transforms.Normalize(mean=[0.5, 0.5, 0.5],\n","                                                                std=[0.5, 0.5, 0.5])])\n","    \n","    val_transforms = transforms.Compose([transforms.Resize((256,256)), \n","                                         transforms.ToTensor(), \n","                                         transforms.Normalize(mean=[0.5, 0.5, 0.5],\n","                                                              std=[0.5, 0.5, 0.5])])\n","\n","    train_dataset = SinDataset(data_dir, transform = train_transforms)\n","    val_dataset = SinDataset(data_dir, transform = val_transforms)\n","\n","    return train_dataset, val_dataset"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QSImyTxJNVU","executionInfo":{"status":"ok","timestamp":1627009442992,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}},"outputId":"30b8173e-9171-44a9-958b-d0021b1df834"},"source":["  # datasets\n","  train_dataset, _ = get_dataset(data_dir)\n","  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1,\n","                                              shuffle = False, num_workers = 8,\n","                                              pin_memory= True)"],"execution_count":73,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"S56ZMfGUKQGN","executionInfo":{"status":"ok","timestamp":1627009442993,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.hidden = 32\n","        self.current_scale = 0\n","\n","        self.discriminators = nn.ModuleList()\n","\n","        temp_disc = nn.ModuleList()\n","\n","        temp_disc.append(nn.Sequential(nn.Conv2d(3, self.hidden, 3, 1, 1),\n","                                       nn.LeakyReLU(0.2)))\n","        for _ in range(3):\n","            temp_disc.append(nn.Sequential(nn.Conv2d(self.hidden, self.hidden, 3, 1, 1),\n","                                           nn.BatchNorm2d(self.hidden),\n","                                           nn.LeakyReLU(0.2)))\n","\n","        temp_disc.append(nn.Sequential(nn.Conv2d(self.hidden, 1, 3, 1, 1)))\n","        \n","        temp_disc = nn.Sequential(*temp_disc)\n","\n","        self.discriminators.append(temp_disc)\n","\n","    def forward(self, x):\n","        out = self.discriminators[self.current_scale](x)\n","        return out\n","\n","    def progress(self):\n","        self.current_scale += 1\n","        if self.current_scale % 4 == 0:\n","            self.hidden *= 2\n","\n","        temp_disc = nn.ModuleList()\n","        temp_disc.append(nn.Sequential(nn.Conv2d(3, self.hidden, 3, 1, 1),\n","                                       nn.LeakyReLU(0.2)))\n","        for _ in range(3):\n","            temp_disc.append(nn.Sequential(nn.Conv2d(self.hidden, self.hidden, 3, 1, 1),\n","                                           nn.BatchNorm2d(self.hidden),\n","                                           nn.LeakyReLU(0.2)))\n","        temp_disc.append(nn.Sequential(nn.Conv2d(self.hidden, 1, 3, 1, 1)))\n","        \n","        temp_disc = nn.Sequential(*temp_disc)\n","\n","        if self.current_scale % 4 != 0:\n","            # continue start learning from prev discriminator's parameters\n","            temp_disc.load_state_dict(self.discriminators[-1].state_dict())\n","\n","        self.discriminators.append(temp_disc)\n","        print(\"PROGRESSION DONE\")"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIHvljFcKcGt","executionInfo":{"status":"ok","timestamp":1627009443433,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["class Generator(nn.Module):\n","    def __init__(self, img_size_min, num_scale, scalefactor = 4/3):\n","        super(Generator, self).__init__()\n","        self.hidden = 32\n","        self.current_scale = 0\n","        self.img_size_min = img_size_min\n","        self.scalefactor = scalefactor\n","        self.num_scale = num_scale\n","\n","        self.size_list = [int(self.img_size_min * (self.scalefactor ** i)) for i in range(num_scale + 1)]\n","        print(f\"size_list : {self.size_list}\")\n","\n","        self.generators = nn.ModuleList()\n","\n","        temp_gene = nn.ModuleList()\n","\n","        temp_gene.append(nn.Sequential(nn.Conv2d(3, self.hidden, 3, 1),\n","                                             nn.BatchNorm2d(self.hidden),\n","                                             nn.LeakyReLU(0.2)))\n","        for _ in range(3):\n","            temp_gene.append(nn.Sequential(nn.Conv2d(self.hidden, self.hidden, 3, 1),\n","                                                 nn.BatchNorm2d(self.hidden),\n","                                                 nn.LeakyReLU(0.2)))\n","        temp_gene.append(nn.Sequential(nn.Conv2d(self.hidden, 3, 3, 1),\n","                                             nn.Tanh()))\n","        \n","        temp_gene = nn.Sequential(*temp_gene)\n","\n","        self.generators.append(temp_gene)\n","\n","    def forward(self, z, img = None):\n","        ret = []\n","        out = None\n","        if img != None:\n","            out = img\n","        else:\n","            out = self.generators[0](z[0])\n","        ret.append(out)\n","        for i in range(1, self.current_scale + 1):\n","            out = F.interpolate(out, (self.size_list[i], self.size_list[i]), mode = 'bilinear', align_corners = True)\n","            prev = out\n","            out = F.pad(out, [5,5,5,5], value = 0)\n","            out += z[i]\n","            out = self.generators[i](out) + prev\n","            ret.append(out)\n","            \n","        return ret\n","\n","    def progress(self):\n","        self.current_scale += 1\n","\n","        if self.current_scale % 4 == 0:\n","            self.hidden *= 2\n","        temp_gene = nn.ModuleList()\n","\n","        temp_gene.append(nn.Sequential(nn.Conv2d(3, self.hidden, 3, 1),\n","                                             nn.BatchNorm2d(self.hidden),\n","                                             nn.LeakyReLU(0.2)))\n","        for _ in range(3):\n","            temp_gene.append(nn.Sequential(nn.Conv2d(self.hidden, self.hidden, 3, 1),\n","                                                 nn.BatchNorm2d(self.hidden),\n","                                                 nn.LeakyReLU(0.2)))\n","        temp_gene.append(nn.Sequential(nn.Conv2d(self.hidden, 3, 3, 1),\n","                                             nn.Tanh()))\n","        \n","        temp_gene = nn.Sequential(*temp_gene)\n","        \n","\n","        if self.current_scale % 4 != 0:\n","            # continue start learning from prev generator's parameters\n","            temp_gene.load_state_dict(self.generators[-1].state_dict())\n","\n","        self.generators.append(temp_gene)"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0esqCqRJjvu","executionInfo":{"status":"ok","timestamp":1627009443433,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["# models\n","scale_factor = 4/3\n","min_max_ratio = img_size_max / img_size_min\n","num_scale = int(np.round(np.log(min_max_ratio)/np.log(scale_factor)))\n","size_list = [int(img_size_min * scale_factor ** i) for i in range(num_scale + 1)]"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-S0pcb-PKKdU","executionInfo":{"status":"ok","timestamp":1627009443766,"user_tz":-540,"elapsed":3,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}},"outputId":"08f3d900-0e86-451d-c2f8-f56cce37f3f4"},"source":["discriminator = Discriminator()\n","generator = Generator(25, num_scale, scale_factor)"],"execution_count":77,"outputs":[{"output_type":"stream","text":["size_list : [25, 33, 44, 59, 79, 105, 140, 187, 249]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bYxkKQAuKkvu","executionInfo":{"status":"ok","timestamp":1627009443767,"user_tz":-540,"elapsed":2,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["torch.cuda.set_device(0)\n","discriminator = discriminator.cuda(0)\n","generator = generator.cuda(0)"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxFBsOnaKq1G","executionInfo":{"status":"ok","timestamp":1627009444873,"user_tz":-540,"elapsed":1,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["# optimizers\n","dis_opt = torch.optim.Adam(discriminator.discriminators[0].parameters(), 5e-4, (0.5, 0.999))\n","gen_opt = torch.optim.Adam(generator.generators[0].parameters(), 5e-4, (0.5, 0.999))"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"xyoHh7ezK2YT","executionInfo":{"status":"ok","timestamp":1627009445737,"user_tz":-540,"elapsed":367,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["stage = 0\n","if load_model is not None:\n","    check_load = open(os.path.join(log_dir, \"checkpoint.txt\"), 'r')\n","    to_restore = check_load.readlines()[-1].strip()\n","    load_file = os.path.join(log_dir, to_restore)\n","    if os.path.isfile(load_file):\n","        print(\"=> loading checkpoint '{}'\".format(load_file))\n","        checkpoint = torch.load(load_file, map_location='cpu')\n","        for _ in range(int(checkpoint['stage'])):\n","            generator.progress()\n","            discriminator.progress()\n","        networks = [discriminator, generator]\n","        \n","        torch.cuda.set_device(0)\n","        networks = [x.cuda(0) for x in networks]\n","\n","        discriminator, generator, = networks\n","        \n","        stage = checkpoint['stage']\n","        print(\"stage: \",stage)\n","        discriminator.load_state_dict(checkpoint['D_state_dict'])\n","        generator.load_state_dict(checkpoint['G_state_dict'])\n","        dis_opt.load_state_dict(checkpoint['d_optimizer'])\n","        gen_opt.load_state_dict(checkpoint['g_optimizer'])\n","        print(\"=> loaded checkpoint '{}' (stage {})\"\n","              .format(load_file, checkpoint['stage']))\n","    else:\n","        print(\"=> no checkpoint found at '{}'\".format(log_dir))"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"id":"SixT7RQzLMbI","executionInfo":{"status":"ok","timestamp":1627009446044,"user_tz":-540,"elapsed":2,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["# Training\n","fixed_latents = [F.pad(torch.randn(batch_size, 3, size_list[0], size_list[0]), [5,5,5,5], value = 0)]\n","zero_latents = [F.pad(torch.zeros(batch_size, 3, size_list[idx], size_list[idx]), [5,5,5,5], value = 0) for idx in range(1, num_scale + 1)]\n","fixed_latents = fixed_latents + zero_latents"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"FfB8e4YaL8pX","executionInfo":{"status":"ok","timestamp":1627009446411,"user_tz":-540,"elapsed":2,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["# util functions\n","def compute_grad_gp(d_out, x_in):\n","    batch_size = x_in.size(0)\n","    grad_dout = autograd.grad(\n","        outputs=d_out.sum(), inputs=x_in,\n","        create_graph=True, retain_graph=True, only_inputs=True)[0]\n","    grad_dout2 = grad_dout.pow(2)\n","    assert(grad_dout2.size() == x_in.size())\n","    reg = grad_dout2.view(batch_size, -1).sum(1)\n","    return reg\n","\n","\n","def compute_grad_gp_wgan(D, x_real, x_fake):\n","    alpha = torch.rand(x_real.size(0), 1, 1, 1).cuda(0)\n","\n","    x_interpolate = ((1 - alpha) * x_real + alpha * x_fake).detach()\n","    x_interpolate.requires_grad = True\n","    d_inter_logit = D(x_interpolate)\n","    grad = torch.autograd.grad(d_inter_logit, x_interpolate,\n","                               grad_outputs=torch.ones_like(d_inter_logit), create_graph=True)[0]\n","\n","    norm = grad.view(grad.size(0), -1).norm(p=2, dim=1)\n","\n","    d_gp = ((norm - 1) ** 2).mean()\n","    return d_gp\n","\n","def save_checkpoint(state, check_list, log_dir, epoch=0):\n","    check_file = os.path.join(log_dir, 'model_{}.ckpt'.format(epoch))\n","    torch.save(state, check_file)\n","    check_list.write('model_{}.ckpt\\n'.format(epoch))\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"4YX3bM2HNFSg","executionInfo":{"status":"ok","timestamp":1627009560772,"user_tz":-540,"elapsed":2,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["from tqdm import trange\n","import torchvision.utils as vutils\n","\n","def train(data_loader, generator, discriminator, d_opt, g_opt, stage_idx, z, size_list, res_dir, gantype, num_scale):\n","    generator.train()\n","    discriminator.train()\n","\n","    epochs = 2000\n","    decay_lr = 1600\n","    train_it = iter(data_loader)\n","    origin = train_it.next()\n","\n","    if torch.cuda.is_available():\n","        for z_idx in range(len(z)):\n","            z[z_idx] = z[z_idx].cuda(0, non_blocking=True)\n","        origin = origin.cuda(0, non_blocking = True)\n","    \n","    x_in = F.interpolate(origin, (size_list[stage_idx], size_list[stage_idx]), mode = 'bilinear', align_corners = True)\n","    vutils.save_image(x_in.detach().cpu(), os.path.join(res_dir, \"ORGINAL_{}.png\".format(stage_idx)), nrow = 1, normalize = True)\n","\n","    x_in_list = [x_in]\n","    for idx in range(1, stage_idx + 1):\n","        x_in_list.append(F.interpolate(origin, (size_list[idx], size_list[idx]), mode = 'bilinear', align_corners = True))\n","\n","    tqdm_train = trange(0, epochs, initial = 0, total = epochs)\n","\n"," \n","    d_losses = AverageMeter()\n","    g_losses = AverageMeter()\n","    for i in tqdm_train:\n","        if i == decay_lr:\n","            for params in d_opt.param_groups:\n","                params['lr'] *= 0.1\n","\n","            for params in g_opt.param_groups:\n","                params['lr'] *= 0.1\n","            print(\"Generator and Discriminator's learning rate updated\")\n","\n","        # update Generator's weights\n","        for _ in range(3):\n","            g_opt.zero_grad()\n","\n","            out = generator(z)            \n","\n","            g_mse = F.mse_loss(out[-1], x_in)\n","\n","            sqrt_rmse = [1.0]\n","            # calc rmse for every scale (except stage 0)\n","            for idx in range(1, stage_idx + 1):\n","                sqrt_rmse.append(torch.sqrt(F.mse_loss(out[idx], x_in_list[idx])))\n","\n","            # 각 scale의 sqrt_rmse의 값을 랜덤 값에 곱해준 리스트 생성\n","\n","            z_list = [F.pad(sqrt_rmse[z_idx] * torch.randn(1, 3, size_list[z_idx],\n","                                               size_list[z_idx]).cuda(0, non_blocking=True),\n","                            [5, 5, 5, 5], value=0) for z_idx in range(stage_idx + 1)]\n","            \n","            x_fake_list = generator(z_list)\n","            g_fake_logit = discriminator(x_fake_list[-1])\n","            if torch.cuda.is_available():\n","                ones = torch.ones_like(g_fake_logit).cuda(0)\n","            else:\n","                ones = torch.ones_like(g_fake_logit)\n","\n","            if gantype == 'wgangp':\n","                # wgan gp\n","                g_fake = -torch.mean(g_fake_logit, (2, 3))\n","                g_loss = g_fake + 10.0 * g_mse\n","            elif gantype == 'zerogp':\n","                # zero centered GP\n","                g_fake = F.binary_cross_entropy_with_logits(g_fake_logit, ones, reduction='none').mean()\n","                g_loss = g_fake + 100.0 * g_mse\n","\n","            g_loss.backward()\n","            g_opt.step()\n","            g_losses.update(g_loss.item(), x_in.size(0))\n","\n","        # Update Discriminator's weights\n","        for _ in range(3):\n","            x_in.requires_grad = True\n","\n","            d_opt.zero_grad()\n","            x_fake_list = generator(z_list)\n","\n","            d_fake_logit = discriminator(x_fake_list[-1].detach())\n","            d_real_logit = discriminator(x_in)\n","\n","            if torch.cuda.is_available():\n","                ones = torch.ones_like(d_real_logit).cuda(0)\n","                zeros = torch.zeros_like(d_fake_logit).cuda(0)\n","\n","            if gantype == 'wgangp':\n","                # wgan gp\n","                d_fake = torch.mean(d_fake_logit, (2, 3))\n","                d_real = -torch.mean(d_real_logit, (2, 3))\n","                d_gp = compute_grad_gp_wgan(discriminator, x_in, x_fake_list[-1])\n","                d_loss = d_real + d_fake + 0.1 * d_gp\n","\n","            elif gantype == 'zerogp':\n","                # zero centered GP\n","                d_fake = F.binary_cross_entropy_with_logits(d_fake_logit, zeros, reduction='none').mean()\n","                d_real = F.binary_cross_entropy_with_logits(d_real_logit, ones, reduction='none').mean()\n","                d_gp = compute_grad_gp(torch.mean(d_real_logit, (2, 3)), x_in)\n","                d_loss = d_real + d_fake + 10.0 * d_gp\n","\n","            d_loss.backward()\n","            d_opt.step()\n","            d_losses.update(d_loss.item(), x_in.size(0))\n","\n","        tqdm_train.set_description(f'Stage: [{stage_idx}/{num_scale}] Avg Loss: D[{d_losses.avg : .3f}] G[{g_losses.avg : .3f}] RMSE[{sqrt_rmse[-1] : .3f}]')"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCYoY4ALN2ZV","executionInfo":{"status":"ok","timestamp":1627009765196,"user_tz":-540,"elapsed":302,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}}},"source":["def validation_func(data_loader, generator, discriminator, stage_idx, z, size_list, res_dir, validation):\n","    discriminator.eval()\n","    generator.eval()\n","\n","    val_iter = iter(data_loader)\n","    origin = next(val_iter)\n","    \n","    if torch.cuda.is_available():\n","        origin = origin.cuda(0, non_blocking = True)\n","    x_in = F.interpolate(origin, (size_list[stage_idx], size_list[stage_idx]), mode='bilinear', align_corners=True)\n","    vutils.save_image(x_in.detach().cpu(), os.path.join(res_dir, 'ORG_{}.png'.format(stage_idx)),\n","                      nrow=1, normalize=True)\n","    x_in_list = [x_in]\n","    for xidx in range(1, stage_idx + 1):\n","        x_tmp = F.interpolate(origin, (size_list[xidx], size_list[xidx]), mode='bilinear', align_corners=True)\n","        x_in_list.append(x_tmp)\n","\n","    for z_idx in range(len(z)):\n","        z[z_idx] = z[z_idx].cuda(0, non_blocking=True)\n","\n","    with torch.no_grad():\n","        out = generator(z)\n","\n","        # calculate rmse for each scale\n","        rmse_list = [1.0]\n","        for rmseidx in range(1, stage_idx + 1):\n","            rmse = torch.sqrt(F.mse_loss(out[rmseidx], x_in_list[rmseidx]))\n","            if validation:\n","                rmse /= 100.0\n","            rmse_list.append(rmse)\n","        if len(rmse_list) > 1:\n","            rmse_list[-1] = 0.0\n","        if validation:\n","            vutils.save_image(out[-1].detach().cpu(), os.path.join(res_dir, 'validation_REC_{}.png'.format(stage_idx)),\n","                              nrow=1, normalize=True)\n","        else:\n","            vutils.save_image(out[-1].detach().cpu(), os.path.join(res_dir, 'REC_{}.png'.format(stage_idx)),\n","                              nrow=1, normalize=True)\n","\n","        for k in range(50):\n","            z_list = [F.pad(rmse_list[z_idx] * torch.randn(1, 3, size_list[z_idx],\n","                                               size_list[z_idx]).cuda(0, non_blocking=True),\n","                            [5, 5, 5, 5], value=0) for z_idx in range(stage_idx + 1)]\n","            x_fake_list = generator(z_list)\n","            if validation:\n","                vutils.save_image(x_fake_list[-1].detach().cpu(), os.path.join(res_dir, 'validation_GEN_{}_{}.png'.format(stage_idx, k)),\n","                                  nrow=1, normalize=True)\n","            else:\n","                vutils.save_image(x_fake_list[-1].detach().cpu(), os.path.join(res_dir, 'GEN_{}_{}.png'.format(stage_idx, k)),\n","                                  nrow=1, normalize=True)\n","\n"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Ox8wnRjLqiN","executionInfo":{"status":"ok","timestamp":1627015614182,"user_tz":-540,"elapsed":5842833,"user":{"displayName":"김유민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid23UuXOv3ixZ71IOATeg1XS7VWt-AS9mJooLf3Q=s64","userId":"07494986573756898388"}},"outputId":"8208e38d-62eb-4163-8bff-70644e165c1a"},"source":["if validation:\n","    validation_func(train_loader, generator, discriminator, stage, fixed_latents, args)\n","else:        \n","    for stage_idx in range(stage, num_scale + 1):\n","        \n","        train(train_loader, generator, discriminator, dis_opt, gen_opt, stage_idx, fixed_latents, size_list, res_dir, gantype, num_scale)\n","        validation_func(train_loader, generator, discriminator, stage_idx, fixed_latents, size_list, res_dir, validation)\n","        discriminator.progress()\n","        generator.progress()\n","        if torch.cuda.is_available():\n","            discriminator = discriminator.cuda(0)\n","            generator = generator.cuda(0)\n","            \n","        # Update the networks at finest scale\n","        for net_idx in range(generator.current_scale):\n","            for param in generator.generators[net_idx].parameters():\n","                param.requires_grad = False\n","            for param in discriminator.discriminators[net_idx].parameters():\n","                param.requires_grad = False\n","\n","        dis_opt = torch.optim.Adam(discriminator.discriminators[discriminator.current_scale].parameters(),\n","                                    5e-4, (0.5, 0.999))\n","        gen_opt = torch.optim.Adam(generator.generators[generator.current_scale].parameters(),\n","                                    5e-4, (0.5, 0.999))\n","\n","\n","        if stage_idx == 0:            \n","            check_list = open(os.path.join(log_dir, \"checkpoint.txt\"), \"a+\")\n","\n","        save_checkpoint({\n","            'stage': stage_idx + 1,\n","            'D_state_dict': discriminator.state_dict(),\n","            'G_state_dict': generator.state_dict(),\n","            'd_optimizer': dis_opt.state_dict(),\n","            'g_optimizer': gen_opt.state_dict()\n","        }, check_list, log_dir, stage_idx + 1)\n","\n","        if stage_idx == num_scale:\n","            check_list.close()"],"execution_count":95,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Stage: [0/8] Avg Loss: D[ 0.063] G[ 5.536] RMSE[ 1.000]:  80%|████████  | 1602/2000 [01:23<00:20, 19.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generator and Discriminator's learning rate updated\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [0/8] Avg Loss: D[ 0.055] G[ 5.667] RMSE[ 1.000]: 100%|██████████| 2000/2000 [01:44<00:00, 19.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["PROGRESSION DONE\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [1/8] Avg Loss: D[ 0.679] G[ 2.714] RMSE[ 0.025]:  80%|████████  | 1603/2000 [01:38<00:24, 16.26it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generator and Discriminator's learning rate updated\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [1/8] Avg Loss: D[ 0.583] G[ 2.946] RMSE[ 0.023]: 100%|██████████| 2000/2000 [02:02<00:00, 16.27it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["PROGRESSION DONE\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [2/8] Avg Loss: D[ 0.702] G[ 2.360] RMSE[ 0.035]:  80%|████████  | 1601/2000 [01:46<00:27, 14.44it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generator and Discriminator's learning rate updated\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [2/8] Avg Loss: D[ 0.602] G[ 2.611] RMSE[ 0.042]: 100%|██████████| 2000/2000 [02:13<00:00, 14.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["PROGRESSION DONE\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [3/8] Avg Loss: D[ 0.815] G[ 2.086] RMSE[ 0.032]:  80%|████████  | 1601/2000 [01:58<00:28, 14.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generator and Discriminator's learning rate updated\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [3/8] Avg Loss: D[ 0.728] G[ 2.290] RMSE[ 0.029]: 100%|██████████| 2000/2000 [02:28<00:00, 13.50it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["PROGRESSION DONE\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [4/8] Avg Loss: D[ 0.953] G[ 1.740] RMSE[ 0.037]:  80%|████████  | 1601/2000 [04:03<00:59,  6.67it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generator and Discriminator's learning rate updated\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [4/8] Avg Loss: D[ 0.828] G[ 1.981] RMSE[ 0.031]: 100%|██████████| 2000/2000 [05:04<00:00,  6.57it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["PROGRESSION DONE\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [5/8] Avg Loss: D[ 0.992] G[ 1.449] RMSE[ 0.032]:  80%|████████  | 1601/2000 [04:56<01:13,  5.45it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generator and Discriminator's learning rate updated\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [5/8] Avg Loss: D[ 0.904] G[ 1.594] RMSE[ 0.024]: 100%|██████████| 2000/2000 [06:10<00:00,  5.39it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["PROGRESSION DONE\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [6/8] Avg Loss: D[ 0.893] G[ 1.483] RMSE[ 0.025]:  80%|████████  | 1600/2000 [12:20<03:04,  2.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generator and Discriminator's learning rate updated\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [6/8] Avg Loss: D[ 0.821] G[ 1.631] RMSE[ 0.023]: 100%|██████████| 2000/2000 [15:24<00:00,  2.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["PROGRESSION DONE\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [7/8] Avg Loss: D[ 0.945] G[ 1.293] RMSE[ 0.024]:  80%|████████  | 1600/2000 [15:46<03:56,  1.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generator and Discriminator's learning rate updated\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [7/8] Avg Loss: D[ 0.888] G[ 1.412] RMSE[ 0.022]: 100%|██████████| 2000/2000 [19:43<00:00,  1.69it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["PROGRESSION DONE\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [8/8] Avg Loss: D[ 1.241] G[ 1.257] RMSE[ 0.022]:  80%|████████  | 1600/2000 [33:46<08:28,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["Generator and Discriminator's learning rate updated\n"],"name":"stdout"},{"output_type":"stream","text":["Stage: [8/8] Avg Loss: D[ 1.263] G[ 1.159] RMSE[ 0.021]: 100%|██████████| 2000/2000 [42:13<00:00,  1.27s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["PROGRESSION DONE\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a7wQCueZTOLw"},"source":[""],"execution_count":null,"outputs":[]}]}